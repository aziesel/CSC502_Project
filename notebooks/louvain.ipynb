{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "LES_MIS_GRAPH = [\n",
    "    (\"Napoleon\", \"Myriel\", 1), \n",
    "    (\"MlleBaptistine\", \"Myriel\", 8), \n",
    "    (\"MmeMagloire\", \"Myriel\", 10), \n",
    "    (\"MmeMagloire\", \"MlleBaptistine\", 6), \n",
    "    (\"CountessDeLo\", \"Myriel\", 1), \n",
    "    (\"Geborand\", \"Myriel\", 1), \n",
    "    (\"Champtercier\", \"Myriel\", 1), \n",
    "    (\"Cravatte\", \"Myriel\", 1), \n",
    "    (\"Count\", \"Myriel\", 2), \n",
    "    (\"OldMan\", \"Myriel\", 1), \n",
    "    (\"Valjean\", \"Labarre\", 1), \n",
    "    (\"Valjean\", \"MmeMagloire\", 3), \n",
    "    (\"Valjean\", \"MlleBaptistine\", 3), \n",
    "    (\"Valjean\", \"Myriel\", 5), \n",
    "    (\"Marguerite\", \"Valjean\", 1), \n",
    "    (\"MmeDeR\", \"Valjean\", 1), \n",
    "    (\"Isabeau\", \"Valjean\", 1), \n",
    "    (\"Gervais\", \"Valjean\", 1), \n",
    "    (\"Listolier\", \"Tholomyes\", 4), \n",
    "    (\"Fameuil\", \"Tholomyes\", 4), \n",
    "    (\"Fameuil\", \"Listolier\", 4), \n",
    "    (\"Blacheville\", \"Tholomyes\", 4), \n",
    "    (\"Blacheville\", \"Listolier\", 4), \n",
    "    (\"Blacheville\", \"Fameuil\", 4), \n",
    "    (\"Favourite\", \"Tholomyes\", 3), \n",
    "    (\"Favourite\", \"Listolier\", 3), \n",
    "    (\"Favourite\", \"Fameuil\", 3), \n",
    "    (\"Favourite\", \"Blacheville\", 4), \n",
    "    (\"Dahlia\", \"Tholomyes\", 3), \n",
    "    (\"Dahlia\", \"Listolier\", 3), \n",
    "    (\"Dahlia\", \"Fameuil\", 3), \n",
    "    (\"Dahlia\", \"Blacheville\", 3), \n",
    "    (\"Dahlia\", \"Favourite\", 5), \n",
    "    (\"Zephine\", \"Tholomyes\", 3), \n",
    "    (\"Zephine\", \"Listolier\", 3), \n",
    "    (\"Zephine\", \"Fameuil\", 3), \n",
    "    (\"Zephine\", \"Blacheville\", 3), \n",
    "    (\"Zephine\", \"Favourite\", 4), \n",
    "    (\"Zephine\", \"Dahlia\", 4), \n",
    "    (\"Fantine\", \"Tholomyes\", 3), \n",
    "    (\"Fantine\", \"Listolier\", 3), \n",
    "    (\"Fantine\", \"Fameuil\", 3), \n",
    "    (\"Fantine\", \"Blacheville\", 3), \n",
    "    (\"Fantine\", \"Favourite\", 4), \n",
    "    (\"Fantine\", \"Dahlia\", 4), \n",
    "    (\"Fantine\", \"Zephine\", 4), \n",
    "    (\"Fantine\", \"Marguerite\", 2), \n",
    "    (\"Fantine\", \"Valjean\", 9), \n",
    "    (\"MmeThenardier\", \"Fantine\", 2), \n",
    "    (\"MmeThenardier\", \"Valjean\", 7), \n",
    "    (\"Thenardier\", \"MmeThenardier\", 13), \n",
    "    (\"Thenardier\", \"Fantine\", 1), \n",
    "    (\"Thenardier\", \"Valjean\", 12), \n",
    "    (\"Cosette\", \"MmeThenardier\", 4), \n",
    "    (\"Cosette\", \"Valjean\", 31), \n",
    "    (\"Cosette\", \"Tholomyes\", 1), \n",
    "    (\"Cosette\", \"Thenardier\", 1), \n",
    "    (\"Javert\", \"Valjean\", 17), \n",
    "    (\"Javert\", \"Fantine\", 5), \n",
    "    (\"Javert\", \"Thenardier\", 5), \n",
    "    (\"Javert\", \"MmeThenardier\", 1), \n",
    "    (\"Javert\", \"Cosette\", 1), \n",
    "    (\"Fauchelevent\", \"Valjean\", 8), \n",
    "    (\"Fauchelevent\", \"Javert\", 1), \n",
    "    (\"Bamatabois\", \"Fantine\", 1), \n",
    "    (\"Bamatabois\", \"Javert\", 1), \n",
    "    (\"Bamatabois\", \"Valjean\", 2), \n",
    "    (\"Perpetue\", \"Fantine\", 1), \n",
    "    (\"Simplice\", \"Perpetue\", 2), \n",
    "    (\"Simplice\", \"Valjean\", 3), \n",
    "    (\"Simplice\", \"Fantine\", 2), \n",
    "    (\"Simplice\", \"Javert\", 1), \n",
    "    (\"Scaufflaire\", \"Valjean\", 1), \n",
    "    (\"Woman1\", \"Valjean\", 2), \n",
    "    (\"Woman1\", \"Javert\", 1), \n",
    "    (\"Judge\", \"Valjean\", 3), \n",
    "    (\"Judge\", \"Bamatabois\", 2), \n",
    "    (\"Champmathieu\", \"Valjean\", 3), \n",
    "    (\"Champmathieu\", \"Judge\", 3), \n",
    "    (\"Champmathieu\", \"Bamatabois\", 2), \n",
    "    (\"Brevet\", \"Judge\", 2), \n",
    "    (\"Brevet\", \"Champmathieu\", 2), \n",
    "    (\"Brevet\", \"Valjean\", 2), \n",
    "    (\"Brevet\", \"Bamatabois\", 1), \n",
    "    (\"Chenildieu\", \"Judge\", 2), \n",
    "    (\"Chenildieu\", \"Champmathieu\", 2), \n",
    "    (\"Chenildieu\", \"Brevet\", 2), \n",
    "    (\"Chenildieu\", \"Valjean\", 2), \n",
    "    (\"Chenildieu\", \"Bamatabois\", 1), \n",
    "    (\"Cochepaille\", \"Judge\", 2), \n",
    "    (\"Cochepaille\", \"Champmathieu\", 2), \n",
    "    (\"Cochepaille\", \"Brevet\", 2), \n",
    "    (\"Cochepaille\", \"Chenildieu\", 2), \n",
    "    (\"Cochepaille\", \"Valjean\", 2), \n",
    "    (\"Cochepaille\", \"Bamatabois\", 1), \n",
    "    (\"Pontmercy\", \"Thenardier\", 1), \n",
    "    (\"Boulatruelle\", \"Thenardier\", 1), \n",
    "    (\"Eponine\", \"MmeThenardier\", 2), \n",
    "    (\"Eponine\", \"Thenardier\", 3), \n",
    "    (\"Anzelma\", \"Eponine\", 2), \n",
    "    (\"Anzelma\", \"Thenardier\", 2), \n",
    "    (\"Anzelma\", \"MmeThenardier\", 1), \n",
    "    (\"Woman2\", \"Valjean\", 3), \n",
    "    (\"Woman2\", \"Cosette\", 1), \n",
    "    (\"Woman2\", \"Javert\", 1), \n",
    "    (\"MotherInnocent\", \"Fauchelevent\", 3), \n",
    "    (\"MotherInnocent\", \"Valjean\", 1), \n",
    "    (\"Gribier\", \"Fauchelevent\", 2), \n",
    "    (\"MmeBurgon\", \"Jondrette\", 1), \n",
    "    (\"Gavroche\", \"MmeBurgon\", 2), \n",
    "    (\"Gavroche\", \"Thenardier\", 1), \n",
    "    (\"Gavroche\", \"Javert\", 1), \n",
    "    (\"Gavroche\", \"Valjean\", 1), \n",
    "    (\"Gillenormand\", \"Cosette\", 3), \n",
    "    (\"Gillenormand\", \"Valjean\", 2), \n",
    "    (\"Magnon\", \"Gillenormand\", 1), \n",
    "    (\"Magnon\", \"MmeThenardier\", 1), \n",
    "    (\"MlleGillenormand\", \"Gillenormand\", 9), \n",
    "    (\"MlleGillenormand\", \"Cosette\", 2), \n",
    "    (\"MlleGillenormand\", \"Valjean\", 2), \n",
    "    (\"MmePontmercy\", \"MlleGillenormand\", 1), \n",
    "    (\"MmePontmercy\", \"Pontmercy\", 1), \n",
    "    (\"MlleVaubois\", \"MlleGillenormand\", 1), \n",
    "    (\"LtGillenormand\", \"MlleGillenormand\", 2), \n",
    "    (\"LtGillenormand\", \"Gillenormand\", 1), \n",
    "    (\"LtGillenormand\", \"Cosette\", 1), \n",
    "    (\"Marius\", \"MlleGillenormand\", 6), \n",
    "    (\"Marius\", \"Gillenormand\", 12), \n",
    "    (\"Marius\", \"Pontmercy\", 1), \n",
    "    (\"Marius\", \"LtGillenormand\", 1), \n",
    "    (\"Marius\", \"Cosette\", 21), \n",
    "    (\"Marius\", \"Valjean\", 19), \n",
    "    (\"Marius\", \"Tholomyes\", 1), \n",
    "    (\"Marius\", \"Thenardier\", 2), \n",
    "    (\"Marius\", \"Eponine\", 5), \n",
    "    (\"Marius\", \"Gavroche\", 4), \n",
    "    (\"BaronessT\", \"Gillenormand\", 1), \n",
    "    (\"BaronessT\", \"Marius\", 1), \n",
    "    (\"Mabeuf\", \"Marius\", 1), \n",
    "    (\"Mabeuf\", \"Eponine\", 1), \n",
    "    (\"Mabeuf\", \"Gavroche\", 1), \n",
    "    (\"Enjolras\", \"Marius\", 7), \n",
    "    (\"Enjolras\", \"Gavroche\", 7), \n",
    "    (\"Enjolras\", \"Javert\", 6), \n",
    "    (\"Enjolras\", \"Mabeuf\", 1), \n",
    "    (\"Enjolras\", \"Valjean\", 4), \n",
    "    (\"Combeferre\", \"Enjolras\", 15), \n",
    "    (\"Combeferre\", \"Marius\", 5), \n",
    "    (\"Combeferre\", \"Gavroche\", 6), \n",
    "    (\"Combeferre\", \"Mabeuf\", 2), \n",
    "    (\"Prouvaire\", \"Gavroche\", 1), \n",
    "    (\"Prouvaire\", \"Enjolras\", 4), \n",
    "    (\"Prouvaire\", \"Combeferre\", 2), \n",
    "    (\"Feuilly\", \"Gavroche\", 2), \n",
    "    (\"Feuilly\", \"Enjolras\", 6), \n",
    "    (\"Feuilly\", \"Prouvaire\", 2), \n",
    "    (\"Feuilly\", \"Combeferre\", 5), \n",
    "    (\"Feuilly\", \"Mabeuf\", 1), \n",
    "    (\"Feuilly\", \"Marius\", 1), \n",
    "    (\"Courfeyrac\", \"Marius\", 9), \n",
    "    (\"Courfeyrac\", \"Enjolras\", 17), \n",
    "    (\"Courfeyrac\", \"Combeferre\", 13), \n",
    "    (\"Courfeyrac\", \"Gavroche\", 7), \n",
    "    (\"Courfeyrac\", \"Mabeuf\", 2), \n",
    "    (\"Courfeyrac\", \"Eponine\", 1), \n",
    "    (\"Courfeyrac\", \"Feuilly\", 6), \n",
    "    (\"Courfeyrac\", \"Prouvaire\", 3), \n",
    "    (\"Bahorel\", \"Combeferre\", 5), \n",
    "    (\"Bahorel\", \"Gavroche\", 5), \n",
    "    (\"Bahorel\", \"Courfeyrac\", 6), \n",
    "    (\"Bahorel\", \"Mabeuf\", 2), \n",
    "    (\"Bahorel\", \"Enjolras\", 4), \n",
    "    (\"Bahorel\", \"Feuilly\", 3), \n",
    "    (\"Bahorel\", \"Prouvaire\", 2), \n",
    "    (\"Bahorel\", \"Marius\", 1), \n",
    "    (\"Bossuet\", \"Marius\", 5), \n",
    "    (\"Bossuet\", \"Courfeyrac\", 12), \n",
    "    (\"Bossuet\", \"Gavroche\", 5), \n",
    "    (\"Bossuet\", \"Bahorel\", 4), \n",
    "    (\"Bossuet\", \"Enjolras\", 10), \n",
    "    (\"Bossuet\", \"Feuilly\", 6), \n",
    "    (\"Bossuet\", \"Prouvaire\", 2), \n",
    "    (\"Bossuet\", \"Combeferre\", 9), \n",
    "    (\"Bossuet\", \"Mabeuf\", 1), \n",
    "    (\"Bossuet\", \"Valjean\", 1), \n",
    "    (\"Joly\", \"Bahorel\", 5), \n",
    "    (\"Joly\", \"Bossuet\", 7), \n",
    "    (\"Joly\", \"Gavroche\", 3), \n",
    "    (\"Joly\", \"Courfeyrac\", 5), \n",
    "    (\"Joly\", \"Enjolras\", 5), \n",
    "    (\"Joly\", \"Feuilly\", 5), \n",
    "    (\"Joly\", \"Prouvaire\", 2), \n",
    "    (\"Joly\", \"Combeferre\", 5), \n",
    "    (\"Joly\", \"Mabeuf\", 1), \n",
    "    (\"Joly\", \"Marius\", 2), \n",
    "    (\"Grantaire\", \"Bossuet\", 3), \n",
    "    (\"Grantaire\", \"Enjolras\", 3), \n",
    "    (\"Grantaire\", \"Combeferre\", 1), \n",
    "    (\"Grantaire\", \"Courfeyrac\", 2), \n",
    "    (\"Grantaire\", \"Joly\", 2), \n",
    "    (\"Grantaire\", \"Gavroche\", 1), \n",
    "    (\"Grantaire\", \"Bahorel\", 1), \n",
    "    (\"Grantaire\", \"Feuilly\", 1), \n",
    "    (\"Grantaire\", \"Prouvaire\", 1), \n",
    "    (\"MotherPlutarch\", \"Mabeuf\", 3), \n",
    "    (\"Gueulemer\", \"Thenardier\", 5), \n",
    "    (\"Gueulemer\", \"Valjean\", 1), \n",
    "    (\"Gueulemer\", \"MmeThenardier\", 1), \n",
    "    (\"Gueulemer\", \"Javert\", 1), \n",
    "    (\"Gueulemer\", \"Gavroche\", 1), \n",
    "    (\"Gueulemer\", \"Eponine\", 1), \n",
    "    (\"Babet\", \"Thenardier\", 6), \n",
    "    (\"Babet\", \"Gueulemer\", 6), \n",
    "    (\"Babet\", \"Valjean\", 1), \n",
    "    (\"Babet\", \"MmeThenardier\", 1), \n",
    "    (\"Babet\", \"Javert\", 2), \n",
    "    (\"Babet\", \"Gavroche\", 1), \n",
    "    (\"Babet\", \"Eponine\", 1), \n",
    "    (\"Claquesous\", \"Thenardier\", 4), \n",
    "    (\"Claquesous\", \"Babet\", 4), \n",
    "    (\"Claquesous\", \"Gueulemer\", 4), \n",
    "    (\"Claquesous\", \"Valjean\", 1), \n",
    "    (\"Claquesous\", \"MmeThenardier\", 1), \n",
    "    (\"Claquesous\", \"Javert\", 1), \n",
    "    (\"Claquesous\", \"Eponine\", 1), \n",
    "    (\"Claquesous\", \"Enjolras\", 1), \n",
    "    (\"Montparnasse\", \"Javert\", 1), \n",
    "    (\"Montparnasse\", \"Babet\", 2), \n",
    "    (\"Montparnasse\", \"Gueulemer\", 2), \n",
    "    (\"Montparnasse\", \"Claquesous\", 2), \n",
    "    (\"Montparnasse\", \"Valjean\", 1), \n",
    "    (\"Montparnasse\", \"Gavroche\", 1), \n",
    "    (\"Montparnasse\", \"Eponine\", 1), \n",
    "    (\"Montparnasse\", \"Thenardier\", 1), \n",
    "    (\"Toussaint\", \"Cosette\", 2), \n",
    "    (\"Toussaint\", \"Javert\", 1), \n",
    "    (\"Toussaint\", \"Valjean\", 1), \n",
    "    (\"Child1\", \"Gavroche\", 2), \n",
    "    (\"Child2\", \"Gavroche\", 2), \n",
    "    (\"Child2\", \"Child1\", 3), \n",
    "    (\"Brujon\", \"Babet\", 3), \n",
    "    (\"Brujon\", \"Gueulemer\", 3), \n",
    "    (\"Brujon\", \"Thenardier\", 3), \n",
    "    (\"Brujon\", \"Gavroche\", 1), \n",
    "    (\"Brujon\", \"Eponine\", 1), \n",
    "    (\"Brujon\", \"Claquesous\", 1), \n",
    "    (\"Brujon\", \"Montparnasse\", 1), \n",
    "    (\"MmeHucheloup\", \"Bossuet\", 1), \n",
    "    (\"MmeHucheloup\", \"Joly\", 1), \n",
    "    (\"MmeHucheloup\", \"Grantaire\", 1), \n",
    "    (\"MmeHucheloup\", \"Bahorel\", 1), \n",
    "    (\"MmeHucheloup\", \"Courfeyrac\", 1), \n",
    "    (\"MmeHucheloup\", \"Gavroche\", 1), \n",
    "    (\"MmeHucheloup\", \"Enjolras\", 1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/17 19:35:52 WARN Utils: Your hostname, qinning resolves to a loopback address: 127.0.1.1; using 10.0.0.182 instead (on interface wlp5s0)\n",
      "23/03/17 19:35:52 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/17 19:35:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "sc = pyspark.SparkContext.getOrCreate()\n",
    "graph = sc.parallelize(LES_MIS_GRAPH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of partitions: 16\n",
      "23/03/17 19:35:54 WARN SizeEstimator: Failed to check whether UseCompressedOops is set; assuming yes\n",
      "First element in graph: ('Napoleon', 'Myriel', 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(f\"Number of partitions: {str(graph.getNumPartitions())}\")\n",
    "print(f\"First element in graph: {str(graph.first())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:===================================================>     (29 + 3) / 32]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 77, first 10 nodes:\n",
      "['Perpetue', 'Champmathieu', 'Bossuet', 'Claquesous', 'Marguerite', 'Scaufflaire', 'Pontmercy', 'MotherInnocent', 'Combeferre', 'Babet']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "def get_all_nodes(graph: pyspark.rdd.RDD) -> list[str]:\n",
    "    \"\"\"Returns a list of unique nodes in the graph\"\"\"\n",
    "    return graph.map(lambda x: x[0]).distinct().union(graph.map(lambda x: x[1]).distinct()).distinct().collect()\n",
    "\n",
    "all_nodes = get_all_nodes(graph)\n",
    "print(f\"Number of nodes: {len(all_nodes)}, first 10 nodes:\\n{all_nodes[0:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node with max degree: ('Cosette', 'Valjean', 31)\n"
     ]
    }
   ],
   "source": [
    "def get_node_with_max_degree(graph: pyspark.rdd.RDD) -> tuple[str, str, int]:\n",
    "    \"\"\"Returns a tuple of the node with the highest degree and its degree\"\"\"\n",
    "    return graph.reduce(lambda x, y: x if x[2] > y[2] else y)\n",
    "\n",
    "max_degree = get_node_with_max_degree(graph)\n",
    "print(f\"Node with max degree: {max_degree}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster weighted edge volume for Napoleon and Myriel: 1\n",
      "Cluster weighted edge volume for Napoleon and Cosette: 0\n"
     ]
    }
   ],
   "source": [
    "NODE_GROUP = [\"Napoleon\", \"Myriel\"]\n",
    "\n",
    "def get_cluster_volume(graph: pyspark.rdd.RDD, node_group: list[str]) -> int:\n",
    "    \"\"\"\n",
    "    Get the sum of weighted edges between nodes in a node_group/cluster.\n",
    "    \"\"\"\n",
    "    return graph.filter(lambda x: x[0] in node_group and x[1] in node_group).map(lambda x: x[2]).sum()\n",
    "\n",
    "print(f\"Cluster weighted edge volume for Napoleon and Myriel: {get_cluster_volume(graph, ['Napoleon', 'Myriel'])}\") # Should be: 1\n",
    "print(f\"Cluster weighted edge volume for Napoleon and Cosette: {get_cluster_volume(graph, ['Napoleon', 'Cosette'])}\") # Should be 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster cut for Napoleon and Myriel: 30\n",
      "Cluster cut for Napoleon and Cosette: 69\n"
     ]
    }
   ],
   "source": [
    "def get_cluster_cut(graph: pyspark.rdd.RDD, node_group: list[str]) -> int:\n",
    "    \"\"\"\n",
    "    Get the sum of weighted edges between nodes in a node_group/cluster and nodes outside the cluster.\n",
    "    \"\"\"\n",
    "    return graph.filter(lambda x: bool(x[0] in node_group) != bool(x[1] in node_group)).map(lambda x: x[2]).sum()\n",
    "\n",
    "print(f\"Cluster cut for Napoleon and Myriel: {get_cluster_cut(graph, ['Napoleon', 'Myriel'])}\") # Should be: 30\n",
    "print(f\"Cluster cut for Napoleon and Cosette: {get_cluster_cut(graph, ['Napoleon', 'Cosette'])}\") # Should be: 69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.03495240928019035"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from networkx.algorithms.community import modularity\n",
    "from networkx import les_miserables_graph\n",
    "\n",
    "les_mis_graph = les_miserables_graph()\n",
    "partition = [{u} for u in les_mis_graph.nodes()] # Score is computed for all clusterings with one node per cluster\n",
    "modularity(les_mis_graph, partition, resolution=1, weight=\"weight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeit(f):\n",
    "\n",
    "    def timed(*args, **kw):\n",
    "\n",
    "        start = time.time()\n",
    "        result = f(*args, **kw)\n",
    "        end = time.time()\n",
    "        print(f\"function: {f.__name__} took: {end-start:2.4f} seconds\")\n",
    "        \n",
    "        return result\n",
    "\n",
    "    return timed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function: compute_mod_clustering_score took: 26.9206 seconds\n",
      "Total observed modularity score: -2.1398096371207607\n"
     ]
    }
   ],
   "source": [
    "# This takes a really long time to run...\n",
    "@timeit\n",
    "def compute_mod_clustering_score(graph: pyspark.rdd.RDD, node_groups: list[str]) -> float:\n",
    "    \"\"\"\n",
    "    Get the score of a node_group/cluster using the map equation.\n",
    "    \n",
    "    See first equation in Preliminaries section of https://arxiv.org/abs/1710.09605\n",
    "    \"\"\"\n",
    "    vol_sums = [get_cluster_volume(graph, node_group) for node_group in node_groups]\n",
    "    cut_sums = [get_cluster_cut(graph, node_group) for node_group in node_groups]\n",
    "    total_volume = graph.map(lambda x: x[2]).sum()\n",
    "\n",
    "    total = 0\n",
    "    for cut_sum, vol_sum in zip(cut_sums, vol_sums):\n",
    "        total += ((vol_sum - cut_sum) / total_volume) - ((cut_sum ** 2)  / (total_volume ** 2))\n",
    "\n",
    "    return total\n",
    "\n",
    "total = compute_mod_clustering_score(graph, partition)\n",
    "print(f\"Total observed modularity score: {total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function: compute_clustering_score took: 26.5667 seconds\n",
      "Total observed map score: 7.397479562566066\n"
     ]
    }
   ],
   "source": [
    "@timeit\n",
    "def compute_clustering_score(graph: pyspark.rdd.RDD, node_groups: list[str]) -> float:\n",
    "    \"\"\"\n",
    "    Get the score of a node_group/cluster using the map equation.\n",
    "    \n",
    "    See second equation in Preliminaries section of https://arxiv.org/abs/1710.09605\n",
    "    \"\"\"\n",
    "    plogp = lambda x: x * math.log(x) if x > 0 else 0 # computes xlog(x)\n",
    "    vol_sums = [get_cluster_volume(graph, node_group) for node_group in node_groups]\n",
    "    cut_sums = [get_cluster_cut(graph, node_group) for node_group in node_groups]\n",
    "    total_volume = graph.map(lambda x: x[2]).sum()\n",
    "\n",
    "    f_sum = 0\n",
    "    s_sum = 0\n",
    "    t_sum = 0\n",
    "    for cut_sum, vol_sum in zip(cut_sums, vol_sums):\n",
    "        f_sum += cut_sum / total_volume\n",
    "        s_sum += plogp(cut_sum / total_volume)\n",
    "        t_sum += plogp((cut_sum + vol_sum) / total_volume)\n",
    "\n",
    "    return plogp(f_sum) - (2 * s_sum) + t_sum\n",
    "\n",
    "total = compute_clustering_score(graph, partition)\n",
    "print(f\"Total observed map score: {total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_adjacent_node_weights(graph: pyspark.rdd.RDD, node: str) -> int:\n",
    "    \"\"\"\n",
    "    Returns the sum of the weights of neighbouring nodes.\n",
    "    \"\"\"\n",
    "    return graph.filter(lambda x: x[0] == node or x[1] == node).map(lambda x: x[2]).sum()\n",
    "\n",
    "def sum_adjacent_cluster_weights(graph: pyspark.rdd.RDD, node_group: list[str]) -> int:\n",
    "    \"\"\"\n",
    "    Return the sum of the adjacent nodes to a list of nodes. \n",
    "    \"\"\"\n",
    "    return graph.filter(lambda x: x[2] if x[0] in node_group or x[1] in node_group else 0).map(lambda x: x[2]).sum()\n",
    "\n",
    "print(f\"The sum of weights of all edges for Napoleon: {sum_adjacent_node_weights(graph, 'Napoleon')}\")\n",
    "print(f\"The sum of weights of all edges for Cosette: {sum_adjacent_node_weights(graph, 'Cosette')}\")\n",
    "print(f\"The sum of weights for edges connected to both Napoleon and Cosette {sum_adjacent_cluster_weights(graph, ['Napoleon', 'Cosette'])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csc502-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0147c8f441cbbd5705f6a0ae768b3f83c267d6fc5a57c28fe60fc48d36eb859e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
